services:
  # backend:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   container_name: backend
  #   ports:
  #     - "8000:8000"
  #   volumes:
  #     - ./:/app
  #     - /app/.venv/

  #   tty: true
  #   command: >
  #     /bin/sh -c "
  #     if [ ! -f .env ]; then cp .env.example .env; fi &&
  #     make install-uv &&
  #     make install-backend &&
  #     make run-backend
  #     "
  #   networks:
  #     - localnetwork
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/docs"]
  #     interval: 15s
  #     timeout: 3s
  #     retries: 20
  #     start_period: 30s
  #   env_file:
  #     - .env
  #   environment:
  #     BACKEND_HOST: ${BACKEND_HOST:-0.0.0.0}
  #     BACKEND_PORT: ${BACKEND_PORT:-8000}
  #     OLLAMA_MODEL_NAME: ${OLLAMA_MODEL_NAME:-qwen3:0.6b}
  #     OLLAMA_EMBEDDING_MODEL_NAME: ${OLLAMA_EMBEDDING_MODEL_NAME:-all-minilm:l6-v2}
  #     INFERENCE_DEPLOYMENT_NAME: ${INFERENCE_DEPLOYMENT_NAME:-ollama_chat/qwen2.5:0.5b}
  #     INFERENCE_BASE_URL: ${INFERENCE_BASE_URL:-http://ollama:11434}
  #     INFERENCE_API_KEY: ${INFERENCE_API_KEY:-t}
  #     EMBEDDINGS_DEPLOYMENT_NAME: ${EMBEDDINGS_DEPLOYMENT_NAME:-ollama/all-minilm:l6-v2}
  #     EMBEDDINGS_BASE_URL: ${EMBEDDINGS_BASE_URL:-http://ollama:11434}
  #     EMBEDDINGS_API_KEY: ${EMBEDDINGS_API_KEY:-t}
  #     UV_PROJECT_ENVIRONMENT: /venv-backend



  # ollama:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.ollama
  #   entrypoint: [""]
  #   ports:
  #     - 11434:11434
  #   volumes:
  #     - ../genai_template_data/ollama/:/root/.ollama
  #     - ./:/app/
  #   container_name: ollama
  #   pull_policy: always
  #   tty: true

  #   # use tail -f /dev/null in command to keep the container running
  #   command: >
  #     /bin/sh -c "
  #     make download-ollama-models &&
  #     tail -f /dev/null"
  #   env_file:
  #     - .env
  api:
    build:
      context: ./api
    command: uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - ./data/artifacts:/app/artifacts
      # - ./data/db.sqlite:/app/db.sqlite

    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
    env_file:
      - api/.env.dev

  front:
    build:
      context: ./frontend
    working_dir: /app
    command: sh -c "npm install && npm run build && npx serve -s build -l 3000"
    ports:
      - "3000:3000"
    env_file:
      - frontend/.env.development
networks:
  localnetwork:
    driver: bridge
    name: localnetwork
